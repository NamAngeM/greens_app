import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'package:flutter/material.dart';
import 'package:http/http.dart' as http;

/// Service qui g√®re l'int√©gration avec Ollama via l'API Node.js pour le chatbot √©cologique
class OllamaService {
  static OllamaService? _instance;
  bool _isInitialized = false;
  bool _useApiProxy = true; // Par d√©faut, utiliser l'API proxy
  
  // Configuration de l'API
  String _apiBaseUrl = 'http://10.0.2.2:3000/api'; // URL de l'API Node.js avec l'adresse pour √©mulateur Android
  String _modelName = 'llama3:8b'; // Mod√®le par d√©faut plus l√©ger
  
  // Liste des mod√®les disponibles et leurs caract√©ristiques
  final Map<String, Map<String, dynamic>> _modelConfigs = {
    'llama3:8b': {
      'name': 'Llama 3 (8B)',
      'description': 'Mod√®le l√©ger et rapide, id√©al pour r√©ponses simples',
      'size': 'small',
      'ram_required': 4, // Go de RAM requis
      'temperature': 0.5,
      'top_p': 0.7,
      'num_predict': 300,
    },
    'llama3': {
      'name': 'Llama 3 (Standard)',
      'description': 'Mod√®le standard avec bon √©quilibre vitesse/qualit√©',
      'size': 'medium',
      'ram_required': 8,
      'temperature': 0.7,
      'top_p': 0.9,
      'num_predict': 500,
    },
    'llama3:70b': {
      'name': 'Llama 3 (70B)',
      'description': 'Mod√®le complet pour r√©ponses d√©taill√©es',
      'size': 'large',
      'ram_required': 16,
      'temperature': 0.8,
      'top_p': 0.9,
      'num_predict': 800,
    },
  };
  
  // Adresse h√¥te √† utiliser (10.0.2.2 pour √©mulateur Android, localhost sinon)
  final String _hostAddress = Platform.isAndroid ? '10.0.2.2' : 'localhost';
  
  // Cache pour l'historique des conversations
  final Map<String, List<Map<String, String>>> _conversationHistory = {};
  final int _maxHistoryLength = 10; // Nombre maximum de messages dans l'historique
  
  /// Constructeur priv√©
  OllamaService._() {
    // Ajuster les URL en fonction de la plateforme
    _apiBaseUrl = 'http://$_hostAddress:3000/api';
    debugPrint('üîß Configuration pour ${Platform.isAndroid ? "Android" : "Desktop"}, host: $_hostAddress');
  }
  
  /// Singleton pour le service Ollama
  static OllamaService get instance {
    _instance ??= OllamaService._();
    return _instance!;
  }

  /// Initialiser le service en v√©rifiant la connexion √† l'API
  Future<void> initialize() async {
    if (_isInitialized) return;

    debugPrint('üîÑ Tentative d\'initialisation du service OllamaService');
    debugPrint('üì° URL de l\'API: $_apiBaseUrl');

    try {
      // V√©rifier que l'API est accessible
      debugPrint('üîç V√©rification de l\'acc√®s √† l\'API...');
      final response = await http.get(Uri.parse('$_apiBaseUrl/health'))
        .timeout(const Duration(seconds: 5));
      
      debugPrint('üìä R√©ponse du health check: ${response.statusCode} - ${response.body}');
      
      if (response.statusCode == 200) {
        // V√©rifier maintenant la connexion √† Ollama via l'API
        debugPrint('üîç V√©rification de la connexion √† Ollama via l\'API...');
        final ollamaStatus = await http.get(Uri.parse('$_apiBaseUrl/llm/status'))
          .timeout(const Duration(seconds: 5));
        
        debugPrint('üìä R√©ponse du status Ollama: ${ollamaStatus.statusCode} - ${ollamaStatus.body}');
        
        if (ollamaStatus.statusCode == 200) {
          final statusData = jsonDecode(ollamaStatus.body);
          final bool isConnected = statusData['connected'] == true;
          
          debugPrint('üîå Ollama connect√©: $isConnected');
          
          if (isConnected) {
            _isInitialized = true;
            debugPrint('‚úÖ Service API et Ollama initialis√©s avec succ√®s');
          } else {
            debugPrint('‚ùå L\'API est accessible mais Ollama n\'est pas connect√©');
            throw Exception('L\'API est accessible mais Ollama n\'est pas connect√©');
          }
        } else {
          debugPrint('‚ùå Impossible d\'obtenir le statut d\'Ollama via l\'API');
          throw Exception('Impossible d\'obtenir le statut d\'Ollama via l\'API');
        }
      } else {
        debugPrint('‚ùå Impossible de se connecter √† l\'API (code ${response.statusCode})');
        throw Exception('Impossible de se connecter √† l\'API (code ${response.statusCode})');
      }
    } catch (e) {
      debugPrint('‚ùå Erreur lors de l\'initialisation du service: $e');
      // Tentative de connexion directe √† Ollama comme fallback
      _tryDirectOllamaConnection();
    }
  }

  /// Tentative de connexion directe √† Ollama si l'API ne r√©pond pas
  Future<void> _tryDirectOllamaConnection() async {
    debugPrint('üîÑ Tentative de connexion directe √† Ollama...');
    final ollamaDirectUrl = 'http://$_hostAddress:11434';
    debugPrint('üîç Utilisation de l\'URL: $ollamaDirectUrl');
    
    try {
      // V√©rifier l'acc√®s √† Ollama en testant l'API de liste des mod√®les
      // au lieu de /api/health qui peut ne pas exister dans certaines versions
      final response = await http.get(Uri.parse('$ollamaDirectUrl/api/tags'))
        .timeout(const Duration(seconds: 5));
      
      if (response.statusCode == 200) {
        debugPrint('‚úÖ Connexion directe √† Ollama r√©ussie! Utilisation du mode direct.');
        // V√©rifier si le mod√®le llama3 est disponible
        final jsonResponse = jsonDecode(response.body);
        final models = jsonResponse['models'] as List;
        final hasLlama3 = models.any((model) => model['name'] == _modelName);
        
        if (hasLlama3) {
          debugPrint('‚úÖ Mod√®le $_modelName trouv√©!');
        } else {
          debugPrint('‚ö†Ô∏è Mod√®le $_modelName non trouv√©. Veuillez l\'installer avec "ollama pull llama3"');
        }
        
        // Changer l'URL pour pointer directement vers Ollama
        _apiBaseUrl = '$ollamaDirectUrl/api';
        _useApiProxy = false; // D√©sactiver le proxy API puisqu'on acc√®de directement √† Ollama
        debugPrint('üîÑ Mode direct activ√©: _useApiProxy = $_useApiProxy');
        _isInitialized = true;
      } else {
        debugPrint('‚ùå √âchec de la connexion directe √† Ollama (code ${response.statusCode})');
        _isInitialized = false;
      }
    } catch (e) {
      debugPrint('‚ùå Erreur lors de la connexion directe √† Ollama: $e');
      
      // Tentative alternative avec juste un acc√®s au serveur de base
      try {
        final baseResponse = await http.get(Uri.parse(ollamaDirectUrl))
          .timeout(const Duration(seconds: 5));
        
        if (baseResponse.statusCode == 200 || baseResponse.statusCode == 404) {
          // M√™me un 404 sur l'URL de base signifie que le serveur est en cours d'ex√©cution
          debugPrint('‚úÖ Serveur Ollama d√©tect√©! Utilisation du mode direct.');
          _apiBaseUrl = '$ollamaDirectUrl/api';
          _useApiProxy = false; // D√©sactiver le proxy API
          debugPrint('üîÑ Mode direct activ√©: _useApiProxy = $_useApiProxy');
          _isInitialized = true;
        } else {
          _isInitialized = false;
        }
      } catch (e2) {
        debugPrint('‚ùå √âchec de la connexion au serveur Ollama de base: $e2');
        _isInitialized = false;
        
        // Afficher un message sp√©cifique pour Android
        if (Platform.isAndroid) {
          debugPrint('üí° Sur Android, assurez-vous que votre serveur Ollama accepte les connexions externes');
          debugPrint('üí° Conseil: V√©rifiez votre configuration r√©seau et les pare-feu');
        }
      }
    }
  }

  /// Envoyer une requ√™te √† l'API et obtenir une r√©ponse du mod√®le Llama3
  Future<String> getResponse(String text) async {
    debugPrint('üìù Demande de r√©ponse pour: "$text"');
    
    if (!_isInitialized) {
      debugPrint('üîÑ Service non initialis√©, tentative d\'initialisation...');
      await initialize();
      if (!_isInitialized) {
        debugPrint('‚ùå √âchec de l\'initialisation, utilisation du mode hors ligne');
        if (Platform.isAndroid) {
          return "D√©sol√©, je ne peux pas vous r√©pondre pour le moment. Sur un √©mulateur Android, v√©rifiez que:\n" +
                 "1. Votre serveur API est en cours d'ex√©cution sur votre machine h√¥te\n" +
                 "2. Le serveur √©coute sur TOUTES les adresses (0.0.0.0), pas seulement localhost\n" +
                 "3. Aucun pare-feu ne bloque la connexion";
        } else {
          return "D√©sol√©, je ne peux pas vous r√©pondre pour le moment. Veuillez v√©rifier que l'API et le serveur Ollama sont bien d√©marr√©s.";
        }
      }
    }

    try {
      // Utiliser la nouvelle m√©thode generateResponse avec gestion de timeout
      final response = await generateResponse(text, _modelName);
      
      if (response['success'] == true) {
        // V√©rifier s'il y a eu un timeout
        if (response['timeout'] == true) {
          debugPrint('‚ö†Ô∏è Timeout d√©tect√© lors de la g√©n√©ration de la r√©ponse');
          return response['message'];
        }
        return response['message'];
      } else {
        debugPrint('‚ùå Erreur: ${response['message']}');
        return "D√©sol√©, une erreur s'est produite: ${response['message']}";
      }
    } catch (e) {
      debugPrint('‚ùå Erreur lors de l\'appel √† l\'API: $e');
      return "Une erreur de communication s'est produite avec l'API. Veuillez v√©rifier que l'API et Ollama fonctionnent correctement.";
    }
  }
  
  /// Obtenir une r√©ponse directement d'Ollama (mode fallback)
  Future<String> _getDirectOllamaResponse(String text) async {
    try {
      debugPrint('üì§ Envoi direct √† Ollama pour: "$text"');
      final ollamaUrl = 'http://$_hostAddress:11434/api/chat';
      
      // Prompt syst√®me pour l'√©cologie
      final systemPrompt = '''
Tu es GreenBot, un assistant sp√©cialis√© en √©cologie, d√©veloppement durable et protection de l'environnement. Tu as √©t√© con√ßu pour fournir des informations pr√©cises, scientifiquement fond√©es et actuelles sur tous les sujets li√©s √† l'√©cologie.

EXPERTISE:
- Changement climatique et ses impacts
- Biodiversit√© et conservation des √©cosyst√®mes
- √ânergies renouvelables et transition √©nerg√©tique
- Gestion des d√©chets et √©conomie circulaire
- Agriculture durable et syst√®mes alimentaires
- Mobilit√© verte et transport durable
- Consommation responsable et empreinte carbone
- Solutions fond√©es sur la nature

COMPORTEMENT:
- R√©ponds toujours avec des informations bas√©es sur des faits scientifiques valid√©s
- Propose des conseils pratiques et r√©alisables adapt√©s √† diff√©rents contextes
- Pr√©sente les diff√©rents aspects des probl√©matiques √©cologiques, y compris les d√©bats existants
- Utilise un ton positif et encourageant, mais reste r√©aliste sur les d√©fis
- Reconnais les limites de tes connaissances quand c'est le cas
- √âvite le jargon technique et explique les concepts complexes de mani√®re accessible
''';

      // Pr√©parer la requ√™te directe √† Ollama
      final payload = jsonEncode({
        'model': _modelName,
        'messages': [
          {'role': 'system', 'content': systemPrompt},
          {'role': 'user', 'content': text}
        ],
        'stream': false,
        'temperature': 0.5,
        'top_p': 0.8
      });
      
      // Envoyer la requ√™te directement √† Ollama
      final response = await http.post(
        Uri.parse(ollamaUrl),
        headers: {'Content-Type': 'application/json'},
        body: payload
      ).timeout(const Duration(seconds: 60));
      
      debugPrint('üìä R√©ponse d\'Ollama: ${response.statusCode}');
      
      if (response.statusCode == 200) {
        final jsonResponse = jsonDecode(response.body);
        final content = jsonResponse['message']?['content'] ?? '';
        debugPrint('‚úÖ R√©ponse directe d\'Ollama re√ßue (${content.length} caract√®res)');
        return content.toString();
      } else {
        debugPrint('‚ùå Erreur d\'Ollama: ${response.statusCode} - ${response.body}');
        return "D√©sol√©, une erreur s'est produite avec le serveur Ollama (${response.statusCode}).";
      }
    } catch (e) {
      debugPrint('‚ùå Erreur lors de l\'appel direct √† Ollama: $e');
      return "Une erreur de communication s'est produite avec le serveur Ollama.";
    }
  }
  
  /// Obtenir la liste des mod√®les disponibles
  Future<List<String>> getAvailableModels() async {
    debugPrint('üîç R√©cup√©ration des mod√®les disponibles...');
    
    if (!_isInitialized) {
      await initialize();
      if (!_isInitialized) {
        debugPrint('‚ùå Service non initialis√©, impossible de r√©cup√©rer les mod√®les');
        return [];
      }
    }
    
    try {
      // Mode direct √† Ollama
      if (_apiBaseUrl.contains('11434')) {
        final ollamaTagsUrl = 'http://$_hostAddress:11434/api/tags';
        final response = await http.get(Uri.parse(ollamaTagsUrl));
        
        if (response.statusCode == 200) {
          final jsonResponse = jsonDecode(response.body);
          final models = (jsonResponse['models'] as List?)?.map((m) => m['name'].toString()).toList() ?? [];
          debugPrint('‚úÖ Mod√®les r√©cup√©r√©s directement d\'Ollama: $models');
          return models;
        } else {
          debugPrint('‚ùå Erreur lors de la r√©cup√©ration des mod√®les: ${response.statusCode}');
          return [];
        }
      }
      
      // Via l'API
      final response = await http.get(Uri.parse('$_apiBaseUrl/llm/models'));
      
      if (response.statusCode == 200) {
        final jsonResponse = jsonDecode(response.body);
        final List<dynamic> modelsList = jsonResponse['models'] ?? [];
        debugPrint('‚úÖ Mod√®les r√©cup√©r√©s via l\'API: $modelsList');
        return modelsList.map((model) => model.toString()).toList();
      } else {
        debugPrint('‚ùå Erreur lors de la r√©cup√©ration des mod√®les: ${response.statusCode}');
        return [];
      }
    } catch (e) {
      debugPrint('‚ùå Erreur lors de la r√©cup√©ration des mod√®les: $e');
      return [];
    }
  }
  
  /// Tester des param√®tres sp√©cifiques pour le mod√®le
  Future<Map<String, dynamic>> testParameters({
    required String text,
    String? model,
    double? temperature,
    double? topP
  }) async {
    if (!_isInitialized) {
      await initialize();
      if (!_isInitialized) {
        return {'error': 'Service non initialis√©'};
      }
    }
    
    try {
      final Map<String, dynamic> params = {'text': text};
      
      if (model != null) params['model'] = model;
      if (temperature != null) params['temperature'] = temperature;
      if (topP != null) params['topP'] = topP;
      
      final response = await http.post(
        Uri.parse('$_apiBaseUrl/llm/test-parameters'),
        headers: {'Content-Type': 'application/json'},
        body: jsonEncode(params)
      );
      
      if (response.statusCode == 200) {
        return jsonDecode(response.body);
      } else {
        return {'error': 'Erreur ${response.statusCode}'};
      }
    } catch (e) {
      return {'error': e.toString()};
    }
  }
  
  /// V√©rifier si le service est initialis√©
  bool get isInitialized => _isInitialized;
  
  /// V√©rifier si nous utilisons l'API proxy
  bool get useApiProxy => _useApiProxy;
  
  /// D√©finir l'utilisation de l'API proxy
  set useApiProxy(bool value) {
    debugPrint('üîÑ Configuration du mode API proxy: $value');
    _useApiProxy = value;
    // Si on d√©sactive le proxy mais qu'on n'est pas en mode direct,
    // on s'assure que l'URL pointe vers Ollama direct
    if (!value && !_apiBaseUrl.contains('11434')) {
      _apiBaseUrl = 'http://$_hostAddress:11434/api';
      debugPrint('üîÑ URL API mise √† jour pour le mode direct: $_apiBaseUrl');
    }
  }
  
  /// Mettre √† jour l'URL de l'API
  void updateApiUrl(String url) {
    debugPrint('üîÑ Mise √† jour de l\'URL de l\'API: $url');
    _apiBaseUrl = url;
    _isInitialized = false; // Forcer la r√©initialisation avec la nouvelle URL
  }

  Future<Map<String, dynamic>> generateResponse(
    String prompt, 
    String modelName, 
    {
      double? temperature,
      double? topP,
      int? numPredict,
      Function(String chunk)? onResponseChunk,
      String? conversationId
    }
  ) async {
    try {
      // D√©terminer les param√®tres optimaux pour le mod√®le
      final modelConfig = getModelParams(modelName);
      final double finalTemp = temperature ?? modelConfig['temperature'] ?? 0.7;
      final double finalTopP = topP ?? modelConfig['top_p'] ?? 0.9;
      final int finalNumPredict = numPredict ?? modelConfig['num_predict'] ?? 300;
      
      // Identifiant de conversation unique si non fourni
      final String finalConvId = conversationId ?? 'default';
      
      // Obtenir l'historique de la conversation
      final history = getConversationHistory(finalConvId);
      
      // Pr√©parer les messages avec l'historique
      final List<Map<String, String>> messages = [];
      
      // Ajouter le prompt syst√®me s'il n'existe pas dans l'historique
      if (history.isEmpty || history.first['role'] != 'system') {
        final systemPrompt = 'Tu es GreenBot, un assistant √©cologique. R√©ponds de fa√ßon concise en te basant sur des faits scientifiques.';
        messages.add({'role': 'system', 'content': systemPrompt});
        
        // Ajouter au d√©but de l'historique
        if (history.isEmpty) {
          addToHistory(finalConvId, 'system', systemPrompt);
        }
      } else {
        // Utiliser le prompt syst√®me existant
        messages.add(history.first);
      }
      
      // Ajouter l'historique r√©cent (sans le prompt syst√®me)
      if (history.length > 1) {
        messages.addAll(history.sublist(1));
      }
      
      // Ajouter le prompt actuel s'il n'est pas d√©j√† dans l'historique
      if (history.isEmpty || history.last['content'] != prompt) {
        messages.add({'role': 'user', 'content': prompt});
        
        // M√©moriser la question
        addToHistory(finalConvId, 'user', prompt);
      }
      
      debugPrint('üì§ G√©n√©ration avec ${messages.length} messages dans l\'historique');
      
      if (_useApiProxy) {
        debugPrint('üì§ G√©n√©ration via API proxy: $prompt');
        // Utiliser l'API proxy
        // Note: Le streaming via l'API Node.js n√©cessite des modifications c√¥t√© serveur
        // Nous allons donc conserver le comportement actuel pour ce mode
        
        // Construction du payload avec historique (format simplifi√©)
        final Map<String, dynamic> payload = {
          'text': prompt,
          'model': modelName,
          'temperature': finalTemp,
          'topP': finalTopP,
          'num_predict': finalNumPredict
        };
        
        // Ajouter l'historique si disponible
        if (messages.length > 1) {
          payload['history'] = messages;
        }
        
        final response = await http.post(
          Uri.parse('$_apiBaseUrl/llm/generate'),
          headers: {'Content-Type': 'application/json'},
          body: jsonEncode(payload),
        ).timeout(const Duration(seconds: 120));

        // V√©rifier si la r√©ponse contient du HTML au lieu du JSON
        if (response.body.trim().toLowerCase().startsWith('<!doctype html') || 
            response.body.trim().toLowerCase().startsWith('<html')) {
          debugPrint('‚ùå Erreur: La r√©ponse est du HTML au lieu du JSON');
          return {
            'success': false,
            'message': 'Erreur de communication: Le serveur a renvoy√© une page HTML au lieu du JSON. V√©rifiez la configuration du serveur.'
          };
        }

        try {
          final data = jsonDecode(response.body);
          
          // V√©rifier si c'est un timeout de l'API
          if (data['status'] == 'TIMEOUT') {
            debugPrint('‚ö†Ô∏è Timeout d√©tect√© dans la r√©ponse de l\'API');
            return {
              'success': true,
              'timeout': true,
              'message': data['response'] ?? 'La g√©n√©ration de r√©ponse a pris trop de temps.',
            };
          }
          
          if (response.statusCode == 200 && data['status'] == 'OK') {
            debugPrint('‚úÖ R√©ponse API re√ßue avec succ√®s');
            
            // M√©moriser la r√©ponse dans l'historique
            addToHistory(finalConvId, 'assistant', data['response']);
            
            return {
              'success': true,
              'message': data['response'],
            };
          } else {
            debugPrint('‚ùå Erreur API: ${data['message']}');
            return {
              'success': false,
              'message': 'Erreur: ${data['message'] ?? "Une erreur est survenue"}',
            };
          }
        } catch (jsonError) {
          debugPrint('‚ùå Erreur lors du d√©codage JSON: $jsonError');
          debugPrint('‚ùå Contenu re√ßu: ${response.body.substring(0, min(100, response.body.length))}...');
          
          return {
            'success': false,
            'message': 'Erreur lors du d√©codage de la r√©ponse. Format de r√©ponse invalide.',
          };
        }
      } else {
        debugPrint('üì§ G√©n√©ration directe via Ollama: $prompt');
       
        // Si un callback de streaming est fourni, utiliser le mode stream
        if (onResponseChunk != null) {
          debugPrint('üîÑ Utilisation du mode streaming');
          
          final request = http.Request(
            'POST', 
            Uri.parse('http://$_hostAddress:11434/api/chat')
          );
          
          request.headers['Content-Type'] = 'application/json';
          request.body = jsonEncode({
            'model': modelName,
            'messages': messages,
            'stream': true,
            'temperature': finalTemp,
            'top_p': finalTopP,
            'num_predict': finalNumPredict
          });
          
          final streamedResponse = await http.Client().send(request)
              .timeout(const Duration(seconds: 90));
              
          if (streamedResponse.statusCode == 200) {
            String fullResponse = '';
            
            // Traiter le flux de donn√©es
            await for (var chunk in streamedResponse.stream.transform(utf8.decoder)) {
              // Chaque chunk peut contenir plusieurs lignes JSON
              final lines = chunk.split('\n').where((line) => line.isNotEmpty);
              
              for (final line in lines) {
                try {
                  final data = jsonDecode(line);
                  if (data.containsKey('message') && 
                      data['message'].containsKey('content') &&
                      data['message']['content'] != null &&
                      data['message']['content'].isNotEmpty) {
                    
                    final content = data['message']['content'];
                    onResponseChunk(content);
                    fullResponse += content;
                  }
                } catch (e) {
                  debugPrint('‚ö†Ô∏è Erreur parsing chunk JSON: $e');
                }
              }
            }
            
            debugPrint('‚úÖ Streaming termin√©, r√©ponse compl√®te g√©n√©r√©e');
            
            // M√©moriser la r√©ponse compl√®te dans l'historique
            addToHistory(finalConvId, 'assistant', fullResponse);
            
            return {
              'success': true,
              'message': fullResponse,
            };
          } else {
            debugPrint('‚ùå Erreur streaming: ${streamedResponse.statusCode}');
            return {
              'success': false,
              'message': 'Erreur lors du streaming: ${streamedResponse.statusCode}',
            };
          }
        } else {
          // Mode non-streaming (code existant)
          final response = await http.post(
            Uri.parse('http://$_hostAddress:11434/api/chat'),
            headers: {'Content-Type': 'application/json'},
            body: jsonEncode({
              'model': modelName,
              'messages': messages,
              'stream': false,
              'temperature': finalTemp,
              'top_p': finalTopP,
              'num_predict': finalNumPredict
            }),
          ).timeout(const Duration(seconds: 90));

          // V√©rifier si la r√©ponse contient du HTML au lieu du JSON
          if (response.body.trim().toLowerCase().startsWith('<!doctype html') || 
              response.body.trim().toLowerCase().startsWith('<html')) {
            debugPrint('‚ùå Erreur: La r√©ponse est du HTML au lieu du JSON');
            return {
              'success': false,
              'message': 'Erreur de communication: Le serveur a renvoy√© une page HTML au lieu du JSON. V√©rifiez que Ollama est en cours d\'ex√©cution.'
            };
          }

          try {
            final data = jsonDecode(response.body);
            if (response.statusCode == 200) {
              debugPrint('‚úÖ R√©ponse directe d\'Ollama re√ßue avec succ√®s');
              
              // M√©moriser la r√©ponse dans l'historique
              final content = data['message']['content'] ?? 'Pas de r√©ponse';
              addToHistory(finalConvId, 'assistant', content);
              
              return {
                'success': true,
                'message': content,
              };
            } else {
              debugPrint('‚ùå Erreur Ollama: ${data['error'] ?? 'Erreur inconnue'}');
              return {
                'success': false,
                'message': 'Erreur: ${data['error'] ?? "Une erreur est survenue"}',
              };
            }
          } catch (jsonError) {
            debugPrint('‚ùå Erreur lors du d√©codage JSON: $jsonError');
            debugPrint('‚ùå Contenu re√ßu: ${response.body.substring(0, min(100, response.body.length))}...');
            
            return {
              'success': false,
              'message': 'Erreur lors du d√©codage de la r√©ponse. Format de r√©ponse invalide.',
            };
          }
        }
      }
    } on TimeoutException {
      debugPrint('‚ö†Ô∏è Timeout lors de la g√©n√©ration de la r√©ponse');
      
      // Si on est en mode API proxy, essayer de passer en mode direct
      if (_useApiProxy) {
        debugPrint('üîÑ Tentative de basculement vers le mode direct apr√®s timeout');
        _useApiProxy = false;
        
        try {
          // Tentative de connexion directe √† Ollama comme fallback
          await _tryDirectOllamaConnection();
          if (_isInitialized) {
            debugPrint('‚úÖ Basculement r√©ussi, nouvelle tentative en mode direct');
            // R√©essayer avec la connexion directe
            return await generateResponse(prompt, modelName, temperature: temperature, topP: topP);
          }
        } catch (e) {
          debugPrint('‚ùå √âchec du basculement vers le mode direct: $e');
        }
      }
      
      return {
        'success': true, // On consid√®re que c'est un succ√®s pour ne pas afficher une erreur
        'timeout': true,
        'message': 'La g√©n√©ration de r√©ponse a pris trop de temps. Veuillez essayer une question plus courte ou plus simple.',
      };
    } catch (e) {
      debugPrint('‚ùå Erreur lors de la g√©n√©ration de la r√©ponse: $e');
      return {
        'success': false,
        'message': 'Erreur: $e',
      };
    }
  }

  /// Test approfondi de diagnostic qui v√©rifie toutes les connexions possibles
  Future<Map<String, dynamic>> runDiagnostic() async {
    debugPrint('üîç D√©marrage du diagnostic approfondi');
    final results = <String, dynamic>{
      'node_api': {
        'success': false,
        'message': 'Non test√©',
        'details': {}
      },
      'direct_ollama': {
        'success': false,
        'message': 'Non test√©',
        'details': {}
      },
      'recommendations': []
    };
    
    // Tester l'API Node.js
    try {
      debugPrint('üîç Test de l\'API Node.js sur $_apiBaseUrl/health');
      final apiUrl = _apiBaseUrl.contains('3000') ? _apiBaseUrl : 'http://$_hostAddress:3000/api';
      
      // Tester la connexion brute d'abord (ping)
      try {
        final pingResponse = await http.get(
          Uri.parse('$apiUrl/health'),
          headers: {'Accept': 'application/json'},
        ).timeout(const Duration(seconds: 5));
        
        results['node_api']['details']['ping'] = {
          'success': pingResponse.statusCode == 200,
          'status_code': pingResponse.statusCode,
          'content_type': pingResponse.headers['content-type'] ?? 'unknown',
          'body_preview': pingResponse.body.length > 100 
              ? '${pingResponse.body.substring(0, 100)}...' 
              : pingResponse.body
        };
        
        if (pingResponse.statusCode == 200) {
          try {
            final pingData = jsonDecode(pingResponse.body);
            results['node_api']['details']['ping']['json_valid'] = true;
            results['node_api']['details']['ping']['data'] = pingData;
          } catch (e) {
            results['node_api']['details']['ping']['json_valid'] = false;
            results['node_api']['details']['ping']['error'] = e.toString();
          }
        }
      } catch (e) {
        results['node_api']['details']['ping'] = {
          'success': false,
          'error': e.toString()
        };
        results['recommendations'].add('Le serveur Node.js ne r√©pond pas. V√©rifiez qu\'il est d√©marr√© avec `npm start`.');
      }
      
      // Tester le statut Ollama via l'API
      try {
        final ollamaStatusResponse = await http.get(
          Uri.parse('$apiUrl/llm/status'),
          headers: {'Accept': 'application/json'},
        ).timeout(const Duration(seconds: 5));
        
        results['node_api']['details']['ollama_status'] = {
          'success': ollamaStatusResponse.statusCode == 200,
          'status_code': ollamaStatusResponse.statusCode,
          'content_type': ollamaStatusResponse.headers['content-type'] ?? 'unknown',
          'body_preview': ollamaStatusResponse.body.length > 100 
              ? '${ollamaStatusResponse.body.substring(0, 100)}...' 
              : ollamaStatusResponse.body
        };
        
        if (ollamaStatusResponse.statusCode == 200) {
          try {
            final statusData = jsonDecode(ollamaStatusResponse.body);
            results['node_api']['details']['ollama_status']['json_valid'] = true;
            results['node_api']['details']['ollama_status']['data'] = statusData;
            results['node_api']['details']['ollama_status']['ollama_connected'] = statusData['connected'] == true;
            
            if (statusData['connected'] != true) {
              results['recommendations'].add('Le serveur Node.js fonctionne mais ne parvient pas √† se connecter √† Ollama.');
            }
          } catch (e) {
            results['node_api']['details']['ollama_status']['json_valid'] = false;
            results['node_api']['details']['ollama_status']['error'] = e.toString();
          }
        }
      } catch (e) {
        results['node_api']['details']['ollama_status'] = {
          'success': false,
          'error': e.toString()
        };
      }
      
      // R√©sum√© global de l'API Node
      final bool pingSuccess = results['node_api']['details']['ping'] != null && 
                               results['node_api']['details']['ping']['success'] == true;
      final bool statusSuccess = results['node_api']['details']['ollama_status'] != null && 
                                 results['node_api']['details']['ollama_status']['success'] == true;
      final bool ollamaConnected = results['node_api']['details']['ollama_status'] != null && 
                                  results['node_api']['details']['ollama_status']['ollama_connected'] == true;
                                  
      results['node_api']['success'] = pingSuccess && statusSuccess && ollamaConnected;
      if (pingSuccess && statusSuccess && ollamaConnected) {
        results['node_api']['message'] = 'L\'API Node.js et Ollama fonctionnent correctement.';
      } else if (pingSuccess && statusSuccess) {
        results['node_api']['message'] = 'L\'API Node.js fonctionne mais Ollama n\'est pas connect√©.';
      } else if (pingSuccess) {
        results['node_api']['message'] = 'L\'API Node.js r√©pond partiellement.';
      } else {
        results['node_api']['message'] = 'L\'API Node.js ne r√©pond pas.';
      }
    } catch (e) {
      results['node_api']['message'] = 'Erreur lors du test de l\'API Node.js: $e';
      results['recommendations'].add('V√©rifiez que le serveur Node.js est d√©marr√© et accessible.');
    }
    
    // Tester Ollama directement
    try {
      debugPrint('üîç Test d\'Ollama direct sur http://$_hostAddress:11434');
      final ollamaDirectUrl = 'http://$_hostAddress:11434';
      
      // Tester la liste des mod√®les
      try {
        final tagsResponse = await http.get(
          Uri.parse('$ollamaDirectUrl/api/tags'),
          headers: {'Accept': 'application/json'},
        ).timeout(const Duration(seconds: 5));
        
        results['direct_ollama']['details']['tags'] = {
          'success': tagsResponse.statusCode == 200,
          'status_code': tagsResponse.statusCode,
          'content_type': tagsResponse.headers['content-type'] ?? 'unknown',
          'body_preview': tagsResponse.body.length > 100 
              ? '${tagsResponse.body.substring(0, 100)}...' 
              : tagsResponse.body
        };
        
        if (tagsResponse.statusCode == 200) {
          try {
            final tagsData = jsonDecode(tagsResponse.body);
            results['direct_ollama']['details']['tags']['json_valid'] = true;
            results['direct_ollama']['details']['tags']['data'] = tagsData;
            
            // V√©rifier si llama3 est pr√©sent
            final models = tagsData['models'] as List? ?? [];
            final hasLlama3 = models.any((model) => model['name'] == 'llama3');
            results['direct_ollama']['details']['tags']['has_llama3'] = hasLlama3;
            
            if (!hasLlama3) {
              results['recommendations'].add('Le mod√®le llama3 n\'est pas install√©. Ex√©cutez `ollama pull llama3` pour l\'installer.');
            }
          } catch (e) {
            results['direct_ollama']['details']['tags']['json_valid'] = false;
            results['direct_ollama']['details']['tags']['error'] = e.toString();
          }
        }
      } catch (e) {
        results['direct_ollama']['details']['tags'] = {
          'success': false,
          'error': e.toString()
        };
        
        // Essayer un ping de base sur le serveur
        try {
          final pingResponse = await http.get(
            Uri.parse(ollamaDirectUrl),
          ).timeout(const Duration(seconds: 5));
          
          results['direct_ollama']['details']['ping'] = {
            'success': pingResponse.statusCode == 200 || pingResponse.statusCode == 404,
            'status_code': pingResponse.statusCode,
            'content_type': pingResponse.headers['content-type'] ?? 'unknown'
          };
          
          if (pingResponse.statusCode == 200 || pingResponse.statusCode == 404) {
            results['recommendations'].add('Ollama r√©pond mais l\'API n\'est pas accessible. V√©rifiez la version d\'Ollama.');
          }
        } catch (pingError) {
          results['direct_ollama']['details']['ping'] = {
            'success': false,
            'error': pingError.toString()
          };
          results['recommendations'].add('Ollama n\'est pas d√©marr√© ou n\'est pas accessible. Ex√©cutez `ollama serve` pour le d√©marrer.');
        }
      }
      
      // R√©sum√© global d'Ollama direct
      final bool tagsSuccess = results['direct_ollama']['details']['tags'] != null && 
                               results['direct_ollama']['details']['tags']['success'] == true;
      final bool hasLlama3 = results['direct_ollama']['details']['tags'] != null && 
                             results['direct_ollama']['details']['tags']['has_llama3'] == true;
      final bool pingSuccess = results['direct_ollama']['details']['ping'] != null && 
                               results['direct_ollama']['details']['ping']['success'] == true;
                               
      results['direct_ollama']['success'] = tagsSuccess && hasLlama3;
      if (tagsSuccess && hasLlama3) {
        results['direct_ollama']['message'] = 'Ollama fonctionne correctement et llama3 est install√©.';
      } else if (tagsSuccess) {
        results['direct_ollama']['message'] = 'Ollama fonctionne, mais llama3 n\'est pas install√©.';
      } else if (pingSuccess) {
        results['direct_ollama']['message'] = 'Ollama r√©pond mais l\'API n\'est pas accessible.';
      } else {
        results['direct_ollama']['message'] = 'Ollama ne r√©pond pas.';
      }
    } catch (e) {
      results['direct_ollama']['message'] = 'Erreur lors du test d\'Ollama: $e';
      results['recommendations'].add('V√©rifiez qu\'Ollama est install√© et d√©marr√© avec `ollama serve`.');
    }
    
    // Ajouter des recommandations globales
    if (!results['node_api']['success'] && !results['direct_ollama']['success']) {
      results['recommendations'].add('Aucune des deux m√©thodes de connexion ne fonctionne. V√©rifiez les configurations r√©seau et pare-feu.');
      
      // V√©rifier l'√©mulateur Android
      if (Platform.isAndroid) {
        results['recommendations'].add('Sur l\'√©mulateur Android, utilisez 10.0.2.2 au lieu de localhost pour les connexions.');
      }
    } else if (results['direct_ollama']['success'] && !results['node_api']['success']) {
      results['recommendations'].add('Utilisez le mode "Connexion directe √† Ollama" dans les param√®tres de l\'application.');
    }
    
    return results;
  }

  /// Interface utilisateur pour afficher le rapport de diagnostic
  static Future<void> showDiagnosticDialog(BuildContext context) async {
    final ollamaService = OllamaService.instance;
    bool isLoading = true;
    Map<String, dynamic> diagnosticResults = {};
    
    // Ouvrir le dialogue avant m√™me d'avoir les r√©sultats
    showDialog(
      context: context,
      barrierDismissible: false,
      builder: (context) {
        return StatefulBuilder(
          builder: (context, setState) {
            return AlertDialog(
              title: const Text('Diagnostic de connexion'),
              content: SizedBox(
                width: double.maxFinite,
                child: isLoading
                    ? const Column(
                        mainAxisSize: MainAxisSize.min,
                        children: [
                          CircularProgressIndicator(),
                          SizedBox(height: 16),
                          Text('Test des connexions en cours...')
                        ],
                      )
                    : SingleChildScrollView(
                        child: Column(
                          mainAxisSize: MainAxisSize.min,
                          crossAxisAlignment: CrossAxisAlignment.start,
                          children: [
                            _buildDiagnosticSection(
                              'API Node.js',
                              diagnosticResults['node_api']['success'],
                              diagnosticResults['node_api']['message'],
                            ),
                            const Divider(),
                            _buildDiagnosticSection(
                              'Connexion directe √† Ollama',
                              diagnosticResults['direct_ollama']['success'],
                              diagnosticResults['direct_ollama']['message'],
                            ),
                            const Divider(),
                            const Text(
                              'Recommandations:',
                              style: TextStyle(fontWeight: FontWeight.bold),
                            ),
                            const SizedBox(height: 8),
                            ...List.generate(
                              (diagnosticResults['recommendations'] as List).length,
                              (index) => Padding(
                                padding: const EdgeInsets.only(bottom: 4),
                                child: Row(
                                  crossAxisAlignment: CrossAxisAlignment.start,
                                  children: [
                                    const Text('‚Ä¢ ', style: TextStyle(fontWeight: FontWeight.bold)),
                                    Expanded(
                                      child: Text(diagnosticResults['recommendations'][index]),
                                    ),
                                  ],
                                ),
                              ),
                            ),
                            if ((diagnosticResults['recommendations'] as List).isEmpty)
                              const Text('Aucune recommandation n√©cessaire.')
                          ],
                        ),
                      ),
              ),
              actions: [
                TextButton(
                  onPressed: () {
                    Navigator.of(context).pop();
                  },
                  child: const Text('Fermer'),
                ),
                if (!isLoading)
                  ElevatedButton(
                    onPressed: () {
                      setState(() {
                        isLoading = true;
                      });
                      
                      // Relancer le diagnostic
                      ollamaService.runDiagnostic().then((results) {
                        setState(() {
                          isLoading = false;
                          diagnosticResults = results;
                        });
                      });
                    },
                    child: const Text('Relancer le test'),
                  ),
              ],
            );
          }
        );
      },
    );
    
    // Lancer le diagnostic
    diagnosticResults = await ollamaService.runDiagnostic();
    
    // Mettre √† jour l'interface
    if (context.mounted) {
      Navigator.of(context).pop(); // Fermer le pr√©c√©dent dialogue
      
      // Rouvrir avec les r√©sultats
      showDialog(
        context: context,
        builder: (context) {
          return AlertDialog(
            title: const Text('Diagnostic de connexion'),
            content: SizedBox(
              width: double.maxFinite,
              child: SingleChildScrollView(
                child: Column(
                  mainAxisSize: MainAxisSize.min,
                  crossAxisAlignment: CrossAxisAlignment.start,
                  children: [
                    _buildDiagnosticSection(
                      'API Node.js',
                      diagnosticResults['node_api']['success'],
                      diagnosticResults['node_api']['message'],
                    ),
                    const Divider(),
                    _buildDiagnosticSection(
                      'Connexion directe √† Ollama',
                      diagnosticResults['direct_ollama']['success'],
                      diagnosticResults['direct_ollama']['message'],
                    ),
                    const Divider(),
                    const Text(
                      'Recommandations:',
                      style: TextStyle(fontWeight: FontWeight.bold),
                    ),
                    const SizedBox(height: 8),
                    ...List.generate(
                      (diagnosticResults['recommendations'] as List).length,
                      (index) => Padding(
                        padding: const EdgeInsets.only(bottom: 4),
                        child: Row(
                          crossAxisAlignment: CrossAxisAlignment.start,
                          children: [
                            const Text('‚Ä¢ ', style: TextStyle(fontWeight: FontWeight.bold)),
                            Expanded(
                              child: Text(diagnosticResults['recommendations'][index]),
                            ),
                          ],
                        ),
                      ),
                    ),
                    if ((diagnosticResults['recommendations'] as List).isEmpty)
                      const Text('Aucune recommandation n√©cessaire.')
                  ],
                ),
              ),
            ),
            actions: [
              TextButton(
                onPressed: () {
                  Navigator.of(context).pop();
                },
                child: const Text('Fermer'),
              ),
              ElevatedButton(
                onPressed: () {
                  Navigator.of(context).pop();
                  showDiagnosticDialog(context); // Relancer le diagnostic
                },
                child: const Text('Relancer le test'),
              ),
            ],
          );
        },
      );
    }
  }
  
  /// Cr√©er une section pour le rapport de diagnostic
  static Widget _buildDiagnosticSection(String title, bool isSuccess, String message) {
    return Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Row(
          children: [
            Icon(
              isSuccess ? Icons.check_circle : Icons.error,
              color: isSuccess ? Colors.green : Colors.red,
            ),
            const SizedBox(width: 8),
            Text(
              title,
              style: const TextStyle(fontWeight: FontWeight.bold),
            ),
          ],
        ),
        const SizedBox(height: 4),
        Text(message),
      ],
    );
  }

  /// Obtenir le mod√®le actuellement utilis√©
  String get currentModel => _modelName;
  
  /// D√©finir le mod√®le √† utiliser
  set currentModel(String modelName) {
    if (_modelConfigs.containsKey(modelName)) {
      _modelName = modelName;
      debugPrint('üîÑ Mod√®le chang√© pour: $_modelName');
    } else {
      debugPrint('‚ö†Ô∏è Mod√®le inconnu: $modelName, utilisation du mod√®le par d√©faut');
    }
  }
  
  /// Obtenir la liste des configurations de mod√®les
  Map<String, Map<String, dynamic>> get modelConfigs => _modelConfigs;
  
  /// Obtenir les param√®tres recommand√©s pour un mod√®le
  Map<String, dynamic> getModelParams(String modelName) {
    final params = _modelConfigs[modelName];
    if (params == null) {
      return _modelConfigs[_modelName] ?? {};
    }
    return params;
  }
  
  /// S√©lectionner automatiquement le meilleur mod√®le en fonction des ressources disponibles
  Future<String> selectBestModel() async {
    // Logique simplifi√©e - en production, il faudrait d√©tecter la RAM disponible
    if (Platform.isAndroid) {
      // Sur Android, privil√©gier le mod√®le l√©ger
      currentModel = 'llama3:8b';
    } else {
      // Sur desktop, on peut tenter le mod√®le standard
      currentModel = 'llama3';
    }
    
    return _modelName;
  }
  
  /// Ajouter un message √† l'historique de conversation
  void addToHistory(String conversationId, String role, String content) {
    if (!_conversationHistory.containsKey(conversationId)) {
      _conversationHistory[conversationId] = [];
    }
    
    _conversationHistory[conversationId]!.add({
      'role': role,
      'content': content
    });
    
    // Limiter la taille de l'historique
    if (_conversationHistory[conversationId]!.length > _maxHistoryLength) {
      // Garder le premier message (syst√®me) et les derniers messages
      final systemPrompt = _conversationHistory[conversationId]!.first;
      _conversationHistory[conversationId]!.removeAt(0);
      _conversationHistory[conversationId]!.removeAt(0);
      _conversationHistory[conversationId]!.insert(0, systemPrompt);
    }
  }
  
  /// Obtenir l'historique de conversation
  List<Map<String, String>> getConversationHistory(String conversationId) {
    return _conversationHistory[conversationId] ?? [];
  }
  
  /// Effacer l'historique de conversation
  void clearConversationHistory(String conversationId) {
    _conversationHistory.remove(conversationId);
  }
}

class ProductCategoryService {
  static String determineCategory(String barcode) {
    if (barcode.startsWith('978') || barcode.startsWith('979'))
      return "Livres & M√©dias";
    else if (RegExp(r'^(000|00[1-9]|0[1-9][0-9])').hasMatch(barcode))
      return "√âlectronique";
    else if (RegExp(r'^(45[0-9])').hasMatch(barcode))
      return "V√™tements & Mode";
    else if (RegExp(r'^(35[0-9])').hasMatch(barcode))
      return "Beaut√© & Cosm√©tiques";
    else if (RegExp(r'^(50[0-9])').hasMatch(barcode))
      return "Produits M√©nagers";
    // Autres cat√©gories sp√©cifiques
    else
      return "Divers"; // Cat√©gorie par d√©faut
  }
  
  static IconData getCategoryIcon(String category) {
    switch(category) {
      case "Livres & M√©dias": return Icons.menu_book;
      case "√âlectronique": return Icons.devices;
      case "V√™tements & Mode": return Icons.checkroom;
      case "Beaut√© & Cosm√©tiques": return Icons.face;
      case "Produits M√©nagers": return Icons.cleaning_services;
      case "Alimentation": return Icons.restaurant;
      default: return Icons.category;
    }
  }
  
  static List<String> getCategorySpecificFields(String category) {
    // Retourne les champs sp√©cifiques √† afficher selon la cat√©gorie
    switch(category) {
      case "Livres & M√©dias": 
        return ["Auteur", "√âditeur", "Pages", "ISBN"];
      case "√âlectronique": 
        return ["Marque", "Mod√®le", "Sp√©cifications", "Garantie"];
      case "V√™tements & Mode": 
        return ["Marque", "Taille", "Mati√®re", "Entretien"];
      // Autres cat√©gories
      default: 
        return ["Description", "Marque", "Caract√©ristiques"];
    }
  }
  
  static IconData getFieldIcon(String field) {
    switch(field) {
      case "Auteur": return Icons.person;
      case "√âditeur": return Icons.business;
      case "Pages": return Icons.book;
      case "ISBN": return Icons.numbers;
      case "Marque": return Icons.branding_watermark;
      case "Mod√®le": return Icons.model_training;
      case "Sp√©cifications": return Icons.settings;
      case "Garantie": return Icons.verified;
      case "Taille": return Icons.format_size;
      case "Mati√®re": return Icons.texture;
      case "Entretien": return Icons.wash;
      default: return Icons.info;
    }
  }
}

// Le fichier se termine ici 